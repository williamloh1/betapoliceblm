as.data.frame(sapply(text.as.data.5, function(x) gsub("\"", "", x)))
as.data.frame(sapply(text.as.data.5, function(x) gsub("\\\"", "", x)))
as.data.frame(sapply(text.as.data.5, function(x) gsub("\\"", "", x)))
as.data.frame(sapply(text.as.data.5, function(x) gsub("\"", "", x)))
text.as.data.4 <- str_replace_all(text.as.data.3, pattern = "\\"\\"", replacement = "")
text.as.data.4 <- str_replace_all(text.as.data.3, pattern = "(\"\")\\1", replacement = "")
text.as.data.3 <- str_replace_all(text.as.data.2, pattern = "[\\$\\.\\!\\/\\:\\#\\-\"]", replacement = "")
text.as.data.3
text.as.data.3
####  Remove the standard english stop words:
stopwords_regex = paste(stopwords('en'), collapse = '\\b|\\b')
####  Remove the standard english stop words:
stopwords_regex = paste(stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
text.as.data.4 <- str_replace_all(text.as.data.3, pattern = stopwords_regex, replacement = "")
####  Add new words:
new.words <- c("see", "people","new","want","one","even","must","need","done","back","just","going","know", "can","said","like","many","like","realdonaldtrump")
text.as.data.6 <- str_replace_all(text.as.data.5, pattern = "(\"\")\\1", replacement = "")
text.as.data.6
as.factor(text.as.data.6)
as.factor(text.as.data.6) == NA
as.factor(text.as.data.6) == NULL
as.factor(text.as.data.6)
levesl(as.factor(text.as.data.6))
levels(as.factor(text.as.data.6))
levels(as.factor(text.as.data.6)[ text.as.data.6=! ""])
levels(as.factor(text.as.data.6)[ text.as.data.6 !=  ""])
(as.factor(text.as.data.6)[ text.as.data.6 !=  ""])
((text.as.data.6)[ text.as.data.6 !=  ""])
text.as.data.6 <- ((text.as.data.6)[ text.as.data.6 !=  ""])
text.as.data.6 <- ((text.as.data.6)[ text.as.data.6 !=  ""])
text.as.data.6 <- str_replace_all(text.as.data.5, pattern = "(\"\")\\1", replacement = "")
text.as.data.7 <- ((text.as.data.6)[ text.as.data.6 !=  ""])
text.as.data.7
text.as.data.2 <- str_replace_all(text.as.data.1, pattern = "\\d", replacement = "")
text.as.data.3 <- str_replace_all(text.as.data.2, pattern = "[\\$\\.\\!\\/\\:\\#\\-\"\\&]", replacement = "")
####  Remove the standard english stop words:
stopwords_regex = paste(stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
text.as.data.4 <- str_replace_all(text.as.data.3, pattern = stopwords_regex, replacement = "")
####  Add new words:
new.words <- c("see", "people","new","want","one","even","must","need","done","back","just","going","know", "can","said","like","many","like","realdonaldtrump")
text.as.data.5 <- c(text.as.data.4, new.words)
text.as.data.6 <- str_replace_all(text.as.data.5, pattern = "(\"\")\\1", replacement = "")
text.as.data.7 <- ((text.as.data.6)[ text.as.data.6 !=  ""])
text.as.data.7
text.as.data.3 <- str_replace_all(text.as.data.2, pattern = "[\\$\\.\\!\\/\\:\\#\\-\"\\&\\;]", replacement = "")
####  Remove the standard english stop words:
stopwords_regex = paste(stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
text.as.data.4 <- str_replace_all(text.as.data.3, pattern = stopwords_regex, replacement = "")
####  Add new words:
new.words <- c("see", "people","new","want","one","even","must","need","done","back","just","going","know", "can","said","like","many","like","realdonaldtrump")
text.as.data.5 <- c(text.as.data.4, new.words)
text.as.data.6 <- str_replace_all(text.as.data.5, pattern = "(\"\")\\1", replacement = "")
text.as.data.7 <- ((text.as.data.6)[ text.as.data.6 !=  ""])
text.as.data.7
text.as.data <- ((text.as.data.6)[ text.as.data.6 !=  ""])
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
install.packages("SnowballC")
#install.packages("SnowballC")
library(SnowballC)
wordcloud(words = text.as.data, freq = d$freq, min.freq = 3,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
text.as.data <- as.data.frame((text.as.data.6)[ text.as.data.6 !=  ""])
text.as.data <- as_tibble((text.as.data.6)[ text.as.data.6 !=  ""])
text.as.data <- text.as.data %>%
mutate(count = n())
View(text.as.data)
text.as.data <- text.as.data %>%
group_by(value) %>%
mutate(count = n())
View(text.as.data)
wordcloud(words = text.as.data$value, text.as.data$freq = $count, min.freq = 3,
wordcloud(words = text.as.data$value, text.as.data$freq = count, min.freq = 3,
wordcloud(words = text.as.data$value, freq = text.as.data$count, min.freq = 3,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
####  I exclude his retweets as they do not reflect his words:
tweets.pop50words <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
select(text)
tweets.pop50words <- unlist(tweets.pop50words)
tweets.pop50words
tweets.pop50words <- str_split(unlist(tweets.pop50words), pattern = " ")
View(tweets.pop50words)
View(tweets.pop50words)
tweets.pop50words <- unlist(str_split(unlist(tweets.pop50words), pattern = " "))
tweets.pop50words
tweets.pop50words <- tweets.pop50words %>%
group_by(value) %>%
mutate(count = n())
tweets.pop50words <- tweets.pop50words %>%
group_by(chracter) %>%
mutate(count = n())
View(tweets.pop.favorite)
tweets.pop50words <- as_tibble(unlist(str_split(unlist(tweets.pop50words), pattern = " ")))
tweets.pop50words <- as_tibble(unlist(str_split(unlist(tweets.pop50words), pattern = " ")))
tweets.pop50words <- tweets.pop50words %>%
group_by(value) %>%
mutate(count = n())
tweets.pop50words <- tweets.pop50words %>%
group_by(value) %>%
mutate(count = n()) %>%
arrange(desc(count)) %>%
filter()
tweets.pop50words <- tweets.pop50words %>%
group_by(value) %>%
mutate(count = n()) %>%
arrange(desc(count)) %>%
slice(1:50)
tweets.pop50words <- tweets.pop50words %>%
group_by(value) %>%
mutate(count = n()) %>%
arrange(desc(count)) %>%
slice(1:50)
View(tweets.pop50words)
####  I exclude his retweets as they do not reflect his words:
tweets.pop50words <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
select(text)
tweets.pop50words <- tweets.pop50words %>%
group_by(value) %>%
mutate(count = n()) %>%
arrange(desc(count))
tweets.pop50words <- tweets.pop50words %>%
group_by(value) %>%
mutate(count = n()) %>%
arrange(desc(count))
tweets.pop50words <- tweets.pop50words %>%
group_by(text) %>%
mutate(count = n()) %>%
arrange(desc(count))
####  I exclude his retweets as they do not reflect his words:
tweets.pop50words <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
select(text)
tweets.pop50words.ready <- as_tibble(unlist(str_split(unlist(tweets.pop50words), pattern = " ")))
tweets.pop50words <- tweets.pop50words %>%
group_by(text) %>%
mutate(count = n()) %>%
arrange(desc(count))
tweets.pop50words <- tweets.pop50words %>%
group_by(text) %>%
mutate(count = n())
View(tweets.pop50words)
####  I exclude his retweets as they do not reflect his words:
tweets.pop50words <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
select(text)
tweets.pop50words.ready <- as_tibble(unlist(str_split(unlist(tweets.pop50words), pattern = " ")))
tweets.pop50words <- tweets.pop50words %>%
group_by(text) %>%
mutate(count = n())
rm(list = ls())
library(tidyverse)
#install.packages('tm')
library(tm)
#install.packages('lubridate')
library(lubridate)
#install.packages('wordcloud')
library(wordcloud)
#install.packages("SnowballC")
library(SnowballC)
tweets <- read_csv('https://politicaldatascience.com/PDS/Datasets/trump_tweets.csv')
tweets.sep <- separate(data = tweets, col = created_at, into = c("date", "time"), sep = " ")
tweets.sep$date<-as.Date(tweets.sep$date, "%m/%d/%Y")
summary(tweets.sep$date)
#### As it can be seen here the coverage is ("2014-01-01" to "2020-02-14").
####  Let's check the most Retweeeted ones:
tweets.pop.retweet <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
arrange(desc(retweet_count)) %>%
select(text) %>%
slice(1:5)
tweets.pop.retweet
####  Let's check the most favorited ones:
tweets.pop.favorite <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
arrange(desc(favorite_count)) %>%
select(text) %>%
slice(1:5)
tweets.pop.favorite
####  Remove extraneous whitespace
text.as.data <- unlist(str_split(c(unlist(tweets.pop.favorite), unlist(tweets.pop.retweet)), " "))
####  Convert everything to lower case:
text.as.data.1 <- str_to_lower(text.as.data)
####  Remove numbers and punctuation:
text.as.data.2 <- str_replace_all(text.as.data.1, pattern = "\\d", replacement = "")
text.as.data.3 <- str_replace_all(text.as.data.2, pattern = "[\\$\\.\\!\\/\\:\\#\\-\"\\&\\;]", replacement = "")
####  Remove the standard english stop words:
stopwords_regex = paste(stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
text.as.data.4 <- str_replace_all(text.as.data.3, pattern = stopwords_regex, replacement = "")
####  Add new words:
new.words <- c("see", "people","new","want","one","even","must","need","done","back","just","going","know", "can","said","like","many","like","realdonaldtrump")
text.as.data.5 <- c(text.as.data.4, new.words)
text.as.data.6 <- str_replace_all(text.as.data.5, pattern = "(\"\")\\1", replacement = "")
text.as.data <- as_tibble((text.as.data.6)[ text.as.data.6 !=  ""])
####  I exclude his retweets as they do not reflect his words:
tweets.pop50words <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
select(text)
tweets.pop50words.ready <- as_tibble(unlist(str_split(unlist(tweets.pop50words), pattern = " ")))
tweets.pop50words <- tweets.pop50words %>%
group_by(text) %>%
mutate(count = n())
tweets.pop50words.ready <- as_tibble(unlist(str_split(unlist(tweets.pop50words), pattern = " ")))
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(text) %>%
mutate(count = n())
####  I exclude his retweets as they do not reflect his words:
tweets.pop50words <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
select(text)
tweets.pop50words.ready <- as_tibble(unlist(str_split(unlist(tweets.pop50words), pattern = " ")))
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(text) %>%
mutate(count = n())
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(value) %>%
mutate(count = n())
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(value) %>%
mutate(count = n()) $>$
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(value) %>%
mutate(count = n()) %>%
filter(unique(value))
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(value) %>%
mutate(count = n()) %>%
filter(unique(value)[1])
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(value) %>%
mutate(count = n()) %>%
sapply(., function(x) unbag(unique(x)))
####  I exclude his retweets as they do not reflect his words:
tweets.pop50words <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
str_to_lower(text) %>%
select(text)
####  I exclude his retweets as they do not reflect his words:
tweets.pop50words <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
mutate(text = str_to_lower(text)) %>%
select(text)
tweets.pop50words.ready <- as_tibble(unlist(str_split(unlist(tweets.pop50words), pattern = " ")))
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(value) %>%
mutate(count = n())
paste(unique(trimws(unlist(tweets.pop50words.ready))),collapse) =
" ")
paste(unique(trimws(unlist(tweets.pop50words.ready))),collapse = " ")
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct()
View(tweets.pop50words.ready.2)
View(tweets.pop50words.ready.2)
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() $>$
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(value)) %>%
slice(1:50)
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count)) %>%
slice(1:50)
View(tweets.pop50words.ready.2)
View(tweets.pop50words.ready)
View(tweets.pop50words.ready.2)
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count)) %>%
slice(1:50)
?slice
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count)) %>%
slice(tweets.pop50words.ready.2, 1:50)
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count))
View(tweets.pop50words.ready.2)
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count)) %>%
filter(count%in%c(1:50))
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count)) %>%
filter(%in%c(1:50))
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count)) %>%
filter(tweets.pop50words.ready.2%in%c(1:50))
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count))
View(tweets.pop50words.ready.2)
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[tweets.pop50words.ready.2$value != NULL]
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[,tweets.pop50words.ready.2$value != NULL]
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[, tweets.pop50words.ready.2$value != ""]
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[tweets.pop50words.ready.2$value != ""]
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count)) %>%
select(value) %>%
slice(1:51)
View(tweets.pop50words.ready.2)
View(tweets.pop50words.ready.2)
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count)) %>%
select(value)
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[1:50,]
View(tweets.pop50words.ready.2)
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count))
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[1:50,]
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[tweets.pop50words.ready.2$value != ""]
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[, tweets.pop50words.ready.2$value != ""]
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[value != ""]
wordcloud(words = tweets.pop50words.ready.2$value, freq = tweets.pop50words.ready.2$count, min.freq = 3,
max.words=, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wc <- wordcloud(words = tweets.pop50words.ready.2$value, freq = tweets.pop50words.ready.2$count, min.freq = 3,
max.words=, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
ggsave("word_cloud.pdf")
wc <- wordcloud(words = tweets.pop50words.ready.2$value, freq = tweets.pop50words.ready.2$count, min.freq = 3,
max.words=, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[1:50,]
wc <- wordcloud(words = tweets.pop50words.ready.2$value, freq = tweets.pop50words.ready.2$count, min.freq = 3,
max.words=, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
install.packages("webshot")
library(webshot)
webshot("tmp.html","my_wordcloud.png", delay =5, vwidth = 480, vheight=480) # changed to png.
library("htmlwidgets")
saveWidget(my_graph,"tmp.html",selfcontained = F)
saveWidget(wc,"tmp.html",selfcontained = F)
wc <- wordcloud2(words = tweets.pop50words.ready.2$value, freq = tweets.pop50words.ready.2$count, min.freq = 3,
max.words=, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wc <- wordcloud(words = tweets.pop50words.ready.2$value, freq = tweets.pop50words.ready.2$count, min.freq = 3,
max.words=, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
####  I exclude his retweets as they do not reflect his words:
####  Also because the question did not specifically asked, I would not exclude the stop words.
tweets.pop50words <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
mutate(text = str_to_lower(text)) %>%
select(text)
####  Getting number of each tweet
tweets.pop50words.ready <- as_tibble(unlist(str_split(unlist(tweets.pop50words), pattern = " ")))
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(value) %>%
mutate(count = n() )
####  Getting rid of dublicates
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count))
####  Getting first 50 words
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[1:50,]
wc <- wordcloud(words = tweets.pop50words.ready.2$value, freq = tweets.pop50words.ready.2$count, min.freq = 3,
max.words=, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
\
####  I exclude his retweets as they do not reflect his words:
####  Also because the question did not specifically asked, I would not exclude the stop words.
tweets.pop50words <- tweets.sep %>%
filter(is_retweet == FALSE) %>%
mutate(text = str_to_lower(text)) %>%
select(text)
####  Getting number of each tweet
tweets.pop50words.ready <- as_tibble(unlist(str_split(unlist(tweets.pop50words), pattern = " ")))
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(value) %>%
mutate(count = n() )
####  Getting rid of dublicates
tweets.pop50words.ready.2 <- tweets.pop50words.ready %>%
distinct() %>%
arrange(desc(count))
####  Getting first 50 words
tweets.pop50words.ready.2 <- tweets.pop50words.ready.2[1:50,]
wc <- wordcloud(words = tweets.pop50words.ready.2$value, freq = tweets.pop50words.ready.2$count, min.freq = 3,
max.words=, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
####  Getting number of each tweet
tweets.pop50words.ready <- tweets.pop50words.ready %>%
group_by(value) %>%
mutate(count = n() )
DTM <- TermDocumentMatrix(tweets.pop50words.ready., control = list(weighting = weightTfIdf))
DTM <- TermDocumentMatrix(tweets.pop50words.ready.2, control = list(weighting = weightTfIdf))
DTM <- TermDocumentMatrix(as.vector(tweets.pop50words.ready.2$value), control = list(weighting = weightTfIdf))
DTM <- TermDocumentMatrix(as.character(tweets.pop50words.ready.2$value), control = list(weighting = weightTfIdf))
DTM <- TermDocumentMatrix(as.character(tweets.pop50words.ready.2$value), control = list(weighting = weightTfIdf))
DTM <- TermDocumentMatrix(tweets.sep, control = list(weighting = weightTfIdf))
DTM <- TermDocumentMatrix(tweets.sep$text, control = list(weighting = weightTfIdf))
DTM <- TermDocumentMatrix(as.list(tweets.sep$text), control = list(weighting = weightTfIdf))
?TermDocumentMatrix
DTM <- TermDocumentMatrix(as.matrixtweets.sep$text), control = list(weighting = weightTfIdf))
DTM <- TermDocumentMatrix(as.matrixtweets.sep$text) control = list(weighting = weightTfIdf))
DTM <- TermDocumentMatrix(as.matrix(tweets.sep$text), control = list(weighting = weightTfIdf))
DTM <- TermDocumentMatrix((tweets.sep$text), control = list(weighting = weightTfIdf))
women <- read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv")
model <- lm(water~reserved, data=women)
summary(model)
low.reserved.coef <- 9.252-qt(0.975, 320)*3.948
high.reserved.coef <- 9.252+qt(0.975, 320)*3.948
paste("The 95% CI for the reserved treatment is between", low.reserved.coef, "and", high.reserved.coef)
#using bootstrapped standard errors
set.seed(999)
bootstrapped.reserved <- list()
#using bootstrapped standard errors
set.seed(999)
bootstrapped.reserved <- list()
for (i in 1:1000){
women.sample <- women[sample (1:nrow(women), nrow(women), replace=T),]
bootstrapped.reserved[[i]] <- coef (lm (water~reserved, data=women.sample))[2]
}
mean(unlist(bootstrapped.reserved))
sd(unlist(bootstrapped.reserved))
low.boot.reserved.coef <- mean(unlist(bootstrapped.reserved))-qt(0.975, 320)*sd(unlist(bootstrapped.reserved))
high.boot.reserved.coef <-mean(unlist(bootstrapped.reserved))+qt(0.975, 320)*sd(unlist(bootstrapped.reserved))
paste("The 95% CI for the bootstrapeed reserved treatment is between", low.boot.reserved.coef, "and", high.boot.reserved.coef)
model.2 <- lm(water~reserved + irrigation + water +female, data=women)
model.2 <- lm(water ~ reserved + irrigation + female, data=women)
summary(model.2)
model.2 <- lm(water ~ reserved + irrigation, data=women)
summary(model.2)
low.reserved.coef <- model.2$coefficients["reserved"]-qnorm(0.975)*sqrt(vcov(model.2)["reserved","reserved"])
high.reserved.coef.2 <- 9.252+qt(0.975, 320)*3.948
low.reserved.coef.2 <- model.2$coefficients["reserved"]-qnorm(0.975)*sqrt(vcov(model.2)["reserved","reserved"])
paste("The 95% CI for the controlled reserved treatment is between", low.reserved.coef.2, "and", high.reserved.coef.2)
rm(list = ls())
#Group assignment
women <- read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv")
model <- lm(water~reserved, data=women)
summary(model)
low.reserved.coef <- 9.252-qt(0.975, 320)*3.948
high.reserved.coef <- 9.252+qt(0.975, 320)*3.948
paste("The 95% CI for the reserved treatment is between", low.reserved.coef, "and", high.reserved.coef)
#using bootstrapped standard errors
set.seed(999)
bootstrapped.reserved <- list()
for (i in 1:1000){
women.sample <- women[sample (1:nrow(women), nrow(women), replace=T),]
bootstrapped.reserved[[i]] <- coef(lm (water~reserved, data=women.sample))[2]
}
mean(unlist(bootstrapped.reserved))
sd(unlist(bootstrapped.reserved))
low.boot.reserved.coef <- mean(unlist(bootstrapped.reserved))-qt(0.975, 320)*sd(unlist(bootstrapped.reserved))
high.boot.reserved.coef <-mean(unlist(bootstrapped.reserved))+qt(0.975, 320)*sd(unlist(bootstrapped.reserved))
paste("The 95% CI for the bootstrapeed reserved treatment is between", low.boot.reserved.coef, "and", high.boot.reserved.coef)
########  With controls
model.2 <- lm(water ~ reserved + irrigation, data=women)
summary(model.2)
low.reserved.coef.2 <- model.2$coefficients["reserved"] - qnorm(0.975)*sqrt(vcov(model.2)["reserved","reserved"])
high.reserved.coef.2 <- model.2$coefficients["reserved"] + qnorm(0.975)*sqrt(vcov(model.2)["reserved","reserved"])
paste("The 95% CI for the controlled reserved
for (i in 1:1000){
women.sample <- women[sample (1:nrow(women), nrow(women), replace=T),]
bootstrapped.reserved.2[[i]] <- coef(lm (water~reserved+irrigation, data=women.sample))[2]
}
bootstrapped.reserved.2 <- list()
for (i in 1:1000){
women.sample <- women[sample (1:nrow(women), nrow(women), replace=T),]
bootstrapped.reserved.2[[i]] <- coef(lm (water~reserved+irrigation, data=women.sample))[2]
}
bootstrapped.reserved <- list()
for (i in 1:1000){
women.sample <- women[sample (1:nrow(women), nrow(women), replace=T),]
bootstrapped.reserved[[i]] <- coef(lm (water~reserved, data=women.sample))[2]
}
mean(unlist(bootstrapped.reserved))
sd(unlist(bootstrapped.reserved))
low.boot.reserved.coef <- mean(unlist(bootstrapped.reserved))-qt(0.975, 320)*sd(unlist(bootstrapped.reserved))
high.boot.reserved.coef <-mean(unlist(bootstrapped.reserved))+qt(0.975, 320)*sd(unlist(bootstrapped.reserved))
paste("The 95% CI for the bootstrapeed reserved treatment is between", low.boot.reserved.coef, "and", high.boot.reserved.coef)
mean(unlist(bootstrapped.reserved.2))
model.2 <- lm(water ~ reserved + irrigation, data=women)
summary(model.2)
low.reserved.coef.2 <- model.2$coefficients["reserved"] - qnorm(0.975)*sqrt(vcov(model.2)["reserved","reserved"])
high.reserved.coef.2 <- model.2$coefficients["reserved"] + qnorm(0.975)*sqrt(vcov(model.2)["reserved","reserved"])
paste("The 95% CI for the controlled reserved treatment is between", low.reserved.coef.2, "and", high.reserved.coef.2)
#using bootstrapped standard errors
set.seed(999)
bootstrapped.reserved.2 <- list()
for (i in 1:1000){
women.sample <- women[sample (1:nrow(women), nrow(women), replace=T),]
bootstrapped.reserved.2[[i]] <- coef(lm (water~reserved+irrigation, data=women.sample))[2]
}
mean(unlist(bootstrapped.reserved.2))
sd(unlist(bootstrapped.reserved.2))
low.boot.reserved.coef.2 <- mean(unlist(bootstrapped.reserved))-qt(0.975, 320)*sd(unlist(bootstrapped.reserved))
low.boot.reserved.coef.2 <- mean(unlist(bootstrapped.reserved.2))-qt(0.975, 320)*sd(unlist(bootstrapped.reserved.2))
high.boot.reserved.coef.2 <-mean(unlist(bootstrapped.reserved.2))+qt(0.975, 320)*sd(unlist(bootstrapped.reserved.2))
paste("The 95% CI for the bootstrapeed reserved treatment is between", low.boot.reserved.coef.2, "and", high.boot.reserved.coef.2)
#group assignment
palestinians<- read.csv("https://jmontgomery.github.io/ProblemSets/longo.csv")
my.model <- lm(militancy~ZA+Sample2009+Sample2009*ZA, data = palestinians)
library(sjPlot)
plot_model(my.model, type="int")
summary(my.model)
